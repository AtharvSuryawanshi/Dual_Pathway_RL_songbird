{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots in a folder\n",
    "save_dir = \"plots\"\n",
    "def remove_prev_files(): # \n",
    "    '''removes previous files in the directory'''\n",
    "    os.makedirs(save_dir, exist_ok = True)\n",
    "    for filename in os.listdir(save_dir):\n",
    "        os.remove(os.path.join(save_dir, filename))\n",
    "remove_prev_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions\n",
    "def gaussian(coordinates, height, mean, spread):\n",
    "    ''' Returns a scalar value for given coordinates in a 2D gaussian distribution'''\n",
    "    x, y = coordinates[0], coordinates[1]\n",
    "    return height * np.exp(-((x-mean[0])**2 + (y-mean[1])**2)/(2*spread**2))\n",
    "\n",
    "def new_sigmoid(x, m=0.0, a=0.0):\n",
    "    \"\"\" Returns an output between -1 and 1 \"\"\"\n",
    "    return (2 / (1 + np.exp(-1*(x-a)*m))) - 1\n",
    "\n",
    "def sigmoid(x, m =0.0 , a=0.0 ):\n",
    "    \"\"\" Returns an output between 0 and 1 \"\"\"\n",
    "    return 1 / (1 + np.exp(-1*(x-a)*m))\n",
    "\n",
    "def sym_lognormal_samples(minimum, maximum, size, mu = 0.01, sigma = 0.5):\n",
    "    \"\"\"\n",
    "    This function generates samples from a combined (original + reflected) lognormal distribution.\n",
    "    Args:\n",
    "        mu (float): Mean of the underlying normal distribution.\n",
    "        sigma (float): Standard deviation of the underlying normal distribution.\n",
    "        size (int): Number of samples to generate.\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of samples from the combined lognormal distribution.\n",
    "    \"\"\"\n",
    "    if size == 0:\n",
    "        ValueError('Size cannot be zero')\n",
    "    # Generate lognormal samples with half in one dimension only\n",
    "    samples = np.random.lognormal(mu, sigma, size)\n",
    "    combined_samples = np.concatenate((samples, samples * -1))/4\n",
    "    # randomly remove samples such that size of combined_samples is equal to size\n",
    "    combined_samples = np.random.choice(combined_samples.reshape(-1), size, replace = False)\n",
    "    combined_samples = np.clip(combined_samples, minimum, maximum)\n",
    "    return combined_samples\n",
    "\n",
    "def lognormal_weight(size, mu = 0.01, sigma = 0.5):\n",
    "    '''returns lognormal weights'''\n",
    "    samples = np.random.lognormal(mu, sigma, size)/4\n",
    "    samples = np.clip(samples, 0, 1)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changable parameters\n",
    "# running conditions\n",
    "TRIALS = 1000\n",
    "DAYS = 61 # 60 days of learning and 1 day of testing\n",
    "N_SYLL = 1\n",
    "if N_SYLL > 5 or N_SYLL < 1:\n",
    "    ValueError('Invalid number of syllables')\n",
    "# RANDOM_SEED = 43 #np.random.randint(0, 1000)\n",
    "# print(f'Random seed is {RANDOM_SEED}')\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# modes\n",
    "ANNEALING = True\n",
    "ANNEALING_SLOPE = 4 \n",
    "ANNEALING_MID = 2\n",
    "HEBBIAN_LEARNING = True\n",
    "LOG_NORMAL = True\n",
    "balance_factor = 2\n",
    "BG_influence = True\n",
    "\n",
    "# parameters\n",
    "REWARD_WINDOW = 10\n",
    "BG_NOISE = 0.1\n",
    "\n",
    "# Run paraneters\n",
    "N_DISTRACTORS = 10\n",
    "LEARING_RATE_RL = 0.1\n",
    "LEARNING_RATE_HL = 2e-5 # small increase compared to CODE_8\n",
    "\n",
    "# sigmoid layer parameters\n",
    "BG_SIG_SLOPE = 2.5  # uniform output \n",
    "BG_sig_MID = 0\n",
    "RA_SIG_SLOPE = 18 # most steep such that MC output is not skewed\n",
    "RA_sig_MID = 0\n",
    "# Sigmoid on MC is removed\n",
    "# MC_SIG_SLOPE = 1 # 5 if lesser -> more difficult to climb the hill, assymptotes before \n",
    "# MC_sig_MID = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# layer sizes\n",
    "HVC_SIZE = 100\n",
    "BG_SIZE = 50\n",
    "RA_SIZE = 100 \n",
    "MC_SIZE = 2\n",
    "N_RA_CLUSTERS = MC_SIZE\n",
    "N_BG_CLUSTERS = 2\n",
    "\n",
    "# Model\n",
    "class NN:\n",
    "    def __init__(self, hvc_size, bg_size, ra_size, mc_size):\n",
    "        if LOG_NORMAL:\n",
    "            self.W_hvc_bg = sym_lognormal_samples(minimum = -1, maximum = 1, size = (hvc_size, bg_size)) # changing from -1 to 1 \n",
    "            self.W_hvc_ra = np.zeros((hvc_size, ra_size)) # connections start from 0 and then increase\n",
    "            self.W_bg_ra = lognormal_weight((bg_size, ra_size)) # const from 0 to 1\n",
    "            self.W_ra_mc = lognormal_weight((ra_size, mc_size)) # const from 0 to 1\n",
    "        else:\n",
    "            self.W_hvc_bg = np.random.uniform((hvc_size, bg_size)) # changing from -1 to 1 \n",
    "            self.W_hvc_ra = np.zeros((hvc_size, ra_size)) # connections start from 0 and then increase\n",
    "            self.W_bg_ra = np.random.uniform(0, 1, (bg_size, ra_size)) # const from 0 to 1\n",
    "            self.W_ra_mc = np.random.uniform(0, 1, (ra_size, mc_size)) # const from 0 to 1\n",
    "        # Creating channels\n",
    "        # channel from ra to mc\n",
    "        for i in range(N_RA_CLUSTERS):\n",
    "            segPath = np.diag(np.ones(N_RA_CLUSTERS, int))[i]\n",
    "            self.W_ra_mc[i*ra_size//N_RA_CLUSTERS : (i+1)*ra_size//N_RA_CLUSTERS] *= segPath\n",
    "        # channel from bg to ra such that motor cortex components are independent of each other\n",
    "        for i in range(N_BG_CLUSTERS):\n",
    "            segPath = np.diag(np.ones(N_BG_CLUSTERS, int))[i]\n",
    "            self.W_bg_ra[i*bg_size//N_BG_CLUSTERS : (i+1)*bg_size//N_BG_CLUSTERS] *= [j for j in segPath for r in range(RA_SIZE//N_BG_CLUSTERS)]\n",
    "\n",
    "        self.hvc_size = hvc_size\n",
    "        self.bg_size = bg_size\n",
    "        self.ra_size = ra_size\n",
    "        self.mc_size = mc_size  \n",
    "        self.ra_cluster_size = ra_size // N_RA_CLUSTERS\n",
    "        self.bg_cluster_size = bg_size // N_BG_CLUSTERS\n",
    "        self.bg_influence = BG_influence\n",
    "            \n",
    "    def forward(self, hvc_array):\n",
    "        self.hvc = hvc_array\n",
    "        # count number of 1 in hvc, divide bg by that number\n",
    "        num_ones = np.count_nonzero(hvc_array == 1)\n",
    "        self.bg = new_sigmoid(np.dot(hvc_array/num_ones, self.W_hvc_bg) + np.random.normal(0, BG_NOISE, self.bg_size), m = BG_SIG_SLOPE, a = BG_sig_MID)\n",
    "        self.ra = new_sigmoid(np.dot(self.bg, self.W_bg_ra/np.sum(self.W_bg_ra, axis=0)) * balance_factor * self.bg_influence + np.dot(hvc_array/num_ones, self.W_hvc_ra)* HEBBIAN_LEARNING, m = RA_SIG_SLOPE, a = RA_sig_MID) \n",
    "        self.mc = np.dot(self.ra, self.W_ra_mc/np.sum(self.W_ra_mc, axis=0)) # outputs to +-0.50\n",
    "        ''' even after BG cut off, output should remain still the same'''\n",
    "        # below code is only for testing without sigmoidal functions\n",
    "        # self.mc = new_sigmoid(np.dot(self.ra, self.W_ra_mc/np.sum(self.W_ra_mc, axis=0)), m = MC_SIG_SLOPE, a = MC_sig_MID)\n",
    "        # self.bg = np.dot(hvc_array/num_ones, self.W_hvc_bg)  #outputs to +-0.98\n",
    "        # self.ra = np.dot(self.bg, self.W_bg_ra/np.sum(self.W_bg_ra, axis=0)) * balance_factor  + np.dot(hvc_array/num_ones, self.W_hvc_ra)* HEBBIAN_LEARNING #outputs to +-0.40\n",
    "        return self.mc, self.ra, self.bg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment of running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, hvc_size, bg_size, ra_size, mc_size, seed):\n",
    "        self.hvc_size = hvc_size\n",
    "        self.bg_size = bg_size\n",
    "        self.ra_size = ra_size\n",
    "        self.mc_size = mc_size\n",
    "        self.seed = seed\n",
    "        self.model = NN(hvc_size, bg_size, ra_size, mc_size)\n",
    "        # landscape parameters\n",
    "        self.centers = np.random.uniform(-0.9, 0.9, (N_SYLL, 2))\n",
    "        self.heights = np.random.uniform(0.2, 0.7, (N_SYLL, N_DISTRACTORS))\n",
    "        self.means = np.random.uniform(-1, 1, (N_SYLL,N_DISTRACTORS, 2))\n",
    "        self.spreads = np.random.uniform(0.1, 0.6, (N_SYLL, N_DISTRACTORS))\n",
    "        # data storage\n",
    "        self.rewards = np.zeros((DAYS, TRIALS, N_SYLL))\n",
    "        self.actions = np.zeros((DAYS, TRIALS, N_SYLL, self.mc_size))\n",
    "        self.hvc_bg_array = np.zeros((DAYS, TRIALS, N_SYLL))\n",
    "        self.bg_out = np.zeros((DAYS, TRIALS, N_SYLL))\n",
    "        self.hvc_ra_array = np.zeros((DAYS, TRIALS, N_SYLL))\n",
    "        self.ra_out = np.zeros((DAYS, TRIALS, N_SYLL))\n",
    "        self.dw_day_array = np.zeros((DAYS, N_SYLL))\n",
    "        self.pot_array = np.zeros((DAYS, N_SYLL))\n",
    "        \n",
    "    def get_reward(self, coordinates, syll):\n",
    "        # landscape creation and reward calculation\n",
    "        center = self.centers[syll, :]\n",
    "        reward_scape = gaussian(coordinates, 1, center, 0.3)\n",
    "        if N_DISTRACTORS == 0:\n",
    "            return reward_scape\n",
    "        hills = []\n",
    "        hills.append(reward_scape)\n",
    "        for i in range(N_DISTRACTORS):\n",
    "            height = self.heights[syll, i]\n",
    "            mean = self.means[syll, i,:]\n",
    "            spread = self.spreads[syll, i]\n",
    "            hills.append(gaussian(coordinates, height, mean, spread))\n",
    "        return np.maximum.reduce(hills)\n",
    "     \n",
    "    def run(self, learning_rate, learning_rate_hl, annealing = False):\n",
    "        # modes \n",
    "        self.annealing = annealing\n",
    "        self.model.bg_influence = True\n",
    "        # each day, 1000 trial, n_syll syllables\n",
    "        for day in (range(DAYS)):\n",
    "            dw_day = np.zeros(N_SYLL)\n",
    "            self.model.bg_influence = True\n",
    "            if day >= DAYS-1: \n",
    "                self.model.bg_influence = False # BG lesion on the last day\n",
    "            for iter in range(TRIALS):\n",
    "                for syll in range(N_SYLL):\n",
    "                    # input from HVC is determined by the syllable\n",
    "                    input_hvc = np.zeros(HVC_SIZE)\n",
    "                    input_hvc[syll] = 1\n",
    "                    # reward, action and baseline\n",
    "                    action, ra, bg = self.model.forward(input_hvc)\n",
    "                    reward = self.get_reward(action, syll)\n",
    "                    self.rewards[day, iter, syll] = reward\n",
    "                    self.actions[day, iter, syll,:] = action\n",
    "                    reward_baseline = 0\n",
    "                    if iter < REWARD_WINDOW and iter > 0:\n",
    "                        reward_baseline = np.mean(self.rewards[day, :iter, syll])\n",
    "                    elif iter >= REWARD_WINDOW:\n",
    "                        reward_baseline = np.mean(self.rewards[day, iter-REWARD_WINDOW:iter, syll])\n",
    "                    # Updating weights\n",
    "                    # RL update\n",
    "                    dw_hvc_bg = learning_rate*(reward - reward_baseline)*input_hvc.reshape(self.hvc_size,1)*self.model.bg * self.model.bg_influence # RL update\n",
    "                    self.model.W_hvc_bg += dw_hvc_bg\n",
    "                    # HL update\n",
    "                    dw_hvc_ra = learning_rate_hl*input_hvc.reshape(self.hvc_size,1)*self.model.ra*HEBBIAN_LEARNING # lr is supposed to be much smaller here\n",
    "                    self.model.W_hvc_ra += dw_hvc_ra\n",
    "                    # bound weights between +-1\n",
    "                    self.model.W_hvc_bg = np.clip(self.model.W_hvc_bg, -1, 1)\n",
    "                    self.model.W_hvc_ra = np.clip(self.model.W_hvc_ra, -1, 1)\n",
    "                    # storing values for plotting\n",
    "                    dw_day[syll] += np.mean(np.abs(dw_hvc_bg))\n",
    "                    self.hvc_bg_array[day, iter, syll] = self.model.W_hvc_bg[syll,1]\n",
    "                    self.bg_out[day, iter, syll] = bg[1]\n",
    "                    self.hvc_ra_array[day, iter, syll] = self.model.W_hvc_ra[syll,1]\n",
    "                    self.ra_out[day, iter, syll] = ra[0]\n",
    "            # if day % 1 == 0:   \n",
    "            #     tqdm.write(f'Day: {day}, Action: {action}, Reward: {reward}, Reward Baseline: {reward_baseline}')  \n",
    "            # Annealing\n",
    "            if self.annealing:\n",
    "                for syll in range(N_SYLL):\n",
    "                    ''' input daily sum, output scaling factor for potentiation'''\n",
    "                    # calculating potentiation \n",
    "                    d = dw_day[syll]*100 # scaling up to be comparable\n",
    "                    p = 1 * sigmoid(1*d, m = ANNEALING_SLOPE, a = ANNEALING_MID)\n",
    "                    potentiation_factor = np.zeros((self.hvc_size))\n",
    "                    potentiation_factor[syll] = 1-p \n",
    "                    # implementing night weight changes\n",
    "                    night_noise = np.random.uniform(-1, 1, self.bg_size) # make it lognormal\n",
    "                    dw_night = LEARING_RATE_RL*potentiation_factor.reshape(self.hvc_size,1)*night_noise*10*self.model.bg_influence\n",
    "                    self.model.W_hvc_bg += dw_night\n",
    "                    self.model.W_hvc_bg = (self.model.W_hvc_bg + 1) % 2 -1 # bound between -1 and 1 in cyclical manner\n",
    "                    # storing values\n",
    "                    self.pot_array[day, syll] = 1-p\n",
    "                    self.dw_day_array[day, syll] = d\n",
    "    def save_trajectory(self, syll):\n",
    "        fig, axs = plt.subplots(figsize=(10, 9))\n",
    "        # generate grid \n",
    "        x, y = np.linspace(-1, 1, 50), np.linspace(-1, 1, 50)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = self.get_reward([X, Y], syll)\n",
    "        # Plot contour\n",
    "        cmap = LinearSegmentedColormap.from_list('white_to_green', ['white', 'green'])\n",
    "        contour = axs.contourf(X, Y, Z, levels=10, cmap=cmap)\n",
    "        fig.colorbar(contour, ax=axs, label='Reward')\n",
    "        \n",
    "        # plot trajectory\n",
    "        x_traj, y_traj = zip(*self.actions[:,:, syll,:].reshape(-1, 2))\n",
    "        axs.plot(x_traj[::10], y_traj[::10], 'r', label='Agent Trajectory', alpha = 0.5, linewidth = 0.5) # Plot every 20th point for efficiency\n",
    "        axs.scatter(x_traj[0], y_traj[0], s=20, c='b', label='Starting Point')  # Plot first point as red circle\n",
    "        axs.scatter(x_traj[-5:], y_traj[-5:], s=20, c='r', marker='x', label='Ending Point') # type: ignore\n",
    "        axs.scatter(self.centers[syll, 0], self.centers[syll, 1], s=20, c='y', marker='x', label='target')  # type: ignore\n",
    "        # labels\n",
    "        axs.set_title(f'Contour plot of reward function SEED:{self.seed} syllable: {syll}')\n",
    "        axs.set_xlabel('x')\n",
    "        axs.set_ylabel('y')\n",
    "        axs.legend()\n",
    "        plt.tight_layout()\n",
    "        # Create the \"plots\" directory if it doesn't exist\n",
    "        os.makedirs(save_dir, exist_ok = True)\n",
    "        # Clear previous plots (optional):\n",
    "        # for filename in os.listdir(save_dir):\n",
    "        #     if filename.startswith(\"trajectory\") and filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        #         os.remove(os.path.join(save_dir, filename))\n",
    "        # Save the plot\n",
    "        plt.savefig(os.path.join(save_dir, f\"trajectory_{self.seed}_{syll}.png\"))\n",
    "        plt.close()  # Close the plot to avoid memory leaks\n",
    "        \n",
    "    def save_results(self, syll):\n",
    "        fig, axs = plt.subplots(6, 1, figsize=(10, 15))\n",
    "        axs[0].plot(self.rewards[:,:,syll].reshape(DAYS*TRIALS), '.', markersize=1, linestyle='None')\n",
    "        axs[0].hlines(0.7, 0, DAYS*TRIALS, colors='r', linestyles='dashed')\n",
    "        axs[0].set_ylim(0, 1)\n",
    "        axs[0].set_ylabel('Reward')\n",
    "        axs[1].plot(self.hvc_bg_array[:,:,syll].reshape(DAYS*TRIALS))\n",
    "        axs[1].set_ylim(-1, 1)\n",
    "        axs[1].set_ylabel('HVC BG weights')\n",
    "        axs[2].plot(self.bg_out[:,:,syll].reshape(DAYS*TRIALS),'.', markersize=0.5, linestyle='None')\n",
    "        axs[2].set_ylim(-1, 1)\n",
    "        axs[2].set_ylabel('BG output')\n",
    "        axs[3].plot(self.hvc_ra_array[:,:,syll].reshape(DAYS*TRIALS))\n",
    "        axs[3].set_ylim(-1, 1)\n",
    "        axs[3].set_ylabel('HVC RA weights')\n",
    "        axs[4].plot(self.actions[:,:,syll,0].reshape(DAYS*TRIALS))\n",
    "        axs[4].plot(self.actions[:,:,syll,1].reshape(DAYS*TRIALS))\n",
    "        axs[4].plot(self.centers[syll, 0]*np.ones(TRIALS*DAYS))\n",
    "        axs[4].plot(self.centers[syll, 1]*np.ones(TRIALS*DAYS))\n",
    "        axs[4].legend(['x target', 'y target'])\n",
    "        axs[4].set_ylabel('Motor Output')\n",
    "        axs[4].set_ylim(-1, 1)\n",
    "        axs[5].plot(self.ra_out[:,:,syll].reshape(DAYS*TRIALS))\n",
    "        axs[5].set_ylim(-1, 1)\n",
    "        axs[5].set_ylabel('RA activity')\n",
    "        fig.suptitle(f'Results SEED:{self.seed} syllable: {syll}', fontsize=20)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        # Create the \"plots\" directory if it doesn't exist\n",
    "        os.makedirs(save_dir, exist_ok = True)\n",
    "        # Clear previous plots (optional):\n",
    "        # for filename in os.listdir(save_dir):\n",
    "        #     if filename.startswith(\"results\") and filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        #         os.remove(os.path.join(save_dir, filename))\n",
    "        # Save the plot\n",
    "        plt.savefig(os.path.join(save_dir, f\"results_{self.seed}_{syll}.png\"))\n",
    "        plt.close()  # Close the plot to avoid memory leaks\n",
    "        \n",
    "    def save_dw_day(self, syll):\n",
    "        if ANNEALING:\n",
    "            expanded_dw_day_array = np.zeros((DAYS*TRIALS, N_SYLL))\n",
    "            expanded_pot_array = np.zeros((DAYS*TRIALS, N_SYLL))\n",
    "            # Expand dw_day_array and pot_array to match the size of rewards\n",
    "            expanded_dw_day_array = np.repeat(self.dw_day_array[:, syll], DAYS*TRIALS// len(self.dw_day_array[:, syll]))\n",
    "            expanded_pot_array = np.repeat(self.pot_array[:, syll], DAYS*TRIALS// len(self.pot_array[:, syll]))\n",
    "            plt.title(f'Annealing SEED:{self.seed} syllable: {syll}')\n",
    "            plt.plot(expanded_dw_day_array, markersize=1, label='dW_day')\n",
    "            plt.plot(expanded_pot_array, markersize=1, label='Potentiation factor')\n",
    "            plt.plot(self.rewards[:,:,syll].reshape(DAYS*TRIALS), '.', markersize=1, label='Reward', alpha = 0.1)\n",
    "            plt.xlabel('Days')\n",
    "            plt.ylabel('dW_day')\n",
    "            plt.legend()\n",
    "            # Create the \"plots\" directory if it doesn't exist\n",
    "            os.makedirs(save_dir, exist_ok = True)\n",
    "            # # Clear previous plots (optional):\n",
    "            # for filename in os.listdir(save_dir):\n",
    "            #     if filename.startswith(\"dw\") and filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "            #         os.remove(os.path.join(save_dir, filename))\n",
    "            # Save the plot\n",
    "            plt.savefig(os.path.join(save_dir, f\"dw_{self.seed}_{syll}.png\"))\n",
    "            plt.close()  # Close the plot to avoid memory leaks         \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:34<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# env = Environment(HVC_SIZE, BG_SIZE, RA_SIZE, MC_SIZE, RANDOM_SEED)\n",
    "# env.run(LEARING_RATE_RL, LEARNING_RATE_HL, ANNEALING)\n",
    "# remove_prev_files()\n",
    "# for i in range(N_SYLL):\n",
    "#     env.save_trajectory(i)\n",
    "#     env.save_results(i)\n",
    "#     if ANNEALING:\n",
    "#         env.save_dw_day(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run given seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def build_and_run(seed, annealing, plot):\n",
    "    tqdm.write(f\" Random seed is {seed}\")\n",
    "    np.random.seed(seed)\n",
    "    env = Environment(HVC_SIZE, BG_SIZE, RA_SIZE, MC_SIZE, seed)\n",
    "    env.run(LEARING_RATE_RL, LEARNING_RATE_HL, annealing)\n",
    "    returns = np.zeros(N_SYLL)\n",
    "    for syll in (range(N_SYLL)):\n",
    "        if plot:\n",
    "            env.save_trajectory(syll)\n",
    "            env.save_results(syll)\n",
    "        if annealing:\n",
    "            env.save_dw_day(syll)\n",
    "        rewards = env.rewards[:,:,syll].reshape(DAYS*TRIALS)\n",
    "        returns[syll] = np.mean(rewards[-100:], axis=0) \n",
    "    return returns\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change of parameters for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIALS = 1000\n",
    "DAYS = 61\n",
    "N_SYLL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds:  [7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random seed is 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7, Returns: [0.30750423]\n",
      " Random seed is 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 8, Returns: [0.44803582]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [7,8]\n",
    "print(\"Seeds: \", seeds)\n",
    "remove_prev_files()\n",
    "returns = np.zeros((len(seeds), N_SYLL))\n",
    "for i in tqdm(range(len(seeds))):\n",
    "    seed = seeds[i]\n",
    "    returns[i, :] = build_and_run(seed, annealing=True, plot=True)\n",
    "    tqdm.write(f\"Seed: {seed}, Returns: {returns[i, :]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
